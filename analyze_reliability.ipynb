{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import warp_norm\n",
    "import matplotlib\n",
    "# import sys\n",
    "# sys.path.append(\"./FaceAlignment\")\n",
    "# import face_alignment\n",
    "from skimage import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from model import gaze_network\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "from pt_module import StNet,StRefine\n",
    "from ipdb import set_trace as st\n",
    "import gaze_normalize\n",
    "\n",
    "cam_chen = '/home/hgh/hghData/Datasets/camChen.xml'  # this is camera calibration information file obtained with OpenCV\n",
    "fs_chen = cv2.FileStorage(cam_chen, cv2.FILE_STORAGE_READ)\n",
    "camera_matrix_chen = fs_chen.getNode('Camera_Matrix').mat() # camera calibration information is used for data normalization\n",
    "camera_distortion_chen = fs_chen.getNode('Distortion_Coefficients').mat()\n",
    "\n",
    "cam_tan = '/home/hgh/hghData/Datasets/camTan.xml'  # this is camera calibration information file obtained with OpenCV\n",
    "fs_tan = cv2.FileStorage(cam_tan, cv2.FILE_STORAGE_READ)\n",
    "camera_matrix_tan = fs_tan.getNode('Camera_Matrix').mat() # camera calibration information is used for data normalization\n",
    "camera_distortion_tan = fs_tan.getNode('Distortion_Coefficients').mat()\n",
    "\n",
    "pixel_scale_tan = np.array([0.202, 0.224])\n",
    "pixel_scale_chen = np.array([0.22, 0.235])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对部分数据集做处理并施加调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hgh/hghData/Datasets2/part/2001.jpg\n",
      "(829, 44)\n",
      "/home/hgh/hghData/Datasets2/part/2002.jpg\n",
      "(929, 63)\n",
      "/home/hgh/hghData/Datasets2/part/2003.jpg\n",
      "(1302, 303)\n",
      "/home/hgh/hghData/Datasets2/part/2004.jpg\n",
      "(68, 321)\n",
      "/home/hgh/hghData/Datasets2/part/2005.jpg\n",
      "(178, 246)\n",
      "/home/hgh/hghData/Datasets2/part/2006.jpg\n",
      "(631, 467)\n",
      "/home/hgh/hghData/Datasets2/part/2007.jpg\n",
      "(745, 633)\n",
      "/home/hgh/hghData/Datasets2/part/2008.jpg\n",
      "(29, 372)\n",
      "/home/hgh/hghData/Datasets2/part/2009.jpg\n",
      "(756, 171)\n",
      "/home/hgh/hghData/Datasets2/part/2010.jpg\n",
      "(86, 635)\n",
      "/home/hgh/hghData/Datasets2/part/2101.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2102.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2103.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2104.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2105.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2106.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2107.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2108.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2109.jpg\n",
      "(-1, -1)\n",
      "/home/hgh/hghData/Datasets2/part/2110.jpg\n",
      "(-1, -1)\n"
     ]
    }
   ],
   "source": [
    "image_folder_path = '/home/hgh/hghData/Datasets2/part'\n",
    "save_dir = '/home/hgh/hghData/Datasets2/part_preprocess'\n",
    "csv_file_path = '/home/hgh/hghData/Datasets2/coordinate.csv'\n",
    "df = pd.read_csv(csv_file_path, header=None)\n",
    "preds = gaze_normalize.xmodel()\n",
    "\n",
    "org_data = []\n",
    "#遍历图像文件夹\n",
    "for filename in sorted(os.listdir(image_folder_path), key=lambda x: int(os.path.splitext(x)[0])):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # 构建图像文件的完整路径\n",
    "        image_path = os.path.join(image_folder_path, filename)\n",
    "        print(image_path)\n",
    "        try:\n",
    "            row = df.iloc[int(os.path.splitext(filename)[0]) - 1].tolist()\n",
    "            label = (int(row[3]),int(row[4]))\n",
    "        except:\n",
    "            st()\n",
    "        print(label)\n",
    "        gaze_normalize_new = gaze_normalize.GazeNormalize(filename,label,camera_matrix_tan,camera_distortion_tan,preds)\n",
    "        save_path = os.path.join(save_dir, f'{filename}')\n",
    "        warp_image = gaze_normalize_new.norm(image_folder_path)\n",
    "        # if gaze_normalize_new.err == False:\n",
    "        #     cv2.imwrite(save_path, warp_image)\n",
    "        org_data.append(gaze_normalize_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gaze estimator\n",
      "load the pre-trained model:  ./ckpt/epoch_24_ckpt.pth.tar\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# # 确保欧拉角转换流程无误\n",
    "# for i in range(20):\n",
    "#     print('hr:',org_data[i].hr)\n",
    "#     print('euler:',warp_norm.hr_to_pitchyaw(org_data[i].hr))\n",
    "#     euler = warp_norm.hr_to_pitchyaw(org_data[i].hr) \n",
    "#     print('re hr:', warp_norm.pitchyaw_to_hr(euler))\n",
    "#     print('-----')\n",
    "\n",
    "# 操作流程\n",
    "# 对hr作调整\n",
    "# 对pitch作调整, epi 0.05deg\n",
    "condit_dict = []\n",
    "epi  = 0.05\n",
    "face_model_load = np.loadtxt('./modules/face_model.txt')  # Generic face model with 3D facial landmarks\n",
    "landmark_use = [20, 23, 26, 29, 15, 19]  # we use eye corners and nose conners\n",
    "face_model = face_model_load[landmark_use, :]\n",
    "print('load gaze estimator')\n",
    "model_path = './ckpt/epoch_24_ckpt.pth.tar'\n",
    "model = gaze_network()\n",
    "model.cuda()\n",
    "pre_trained_model_path = model_path\n",
    "if not os.path.isfile(pre_trained_model_path):\n",
    "    print('the pre-trained gaze estimation model does not exist.')\n",
    "    exit(0)\n",
    "else:\n",
    "    print('load the pre-trained model: ', pre_trained_model_path)\n",
    "ckpt = torch.load(pre_trained_model_path)\n",
    "model.load_state_dict(ckpt['model_state'], strict=True)  # load the pre-trained model\n",
    "model.eval()  # change it to the evaluation mode\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(-10,11):\n",
    "        for k in range(3):\n",
    "            temp = copy.deepcopy(org_data[i])\n",
    "            euler = warp_norm.hr_to_pitchyaw(temp.hr)\n",
    "            euler[0,k] += epi*j\n",
    "            temp.hr = warp_norm.pitchyaw_to_hr(euler)\n",
    "            image_warp = temp.xtrans(face_model)\n",
    "            temp.pred(model, image_warp)\n",
    "            temp.vector_to_screen(pixel_scale_tan)\n",
    "            condit_dict.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_tan = np.array([800,0])#tan 1600*825\n",
    "# pred_gc_org[i] = org_tan + pred_gc[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多因素方差分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:            MixedLM Dependent Variable: prediction_x\n",
      "No. Observations: 630     Method:             REML        \n",
      "No. Groups:       10      Scale:              525.9987    \n",
      "Min. group size:  63      Log-Likelihood:     -2896.9324  \n",
      "Max. group size:  63      Converged:          Yes         \n",
      "Mean group size:  63.0                                    \n",
      "----------------------------------------------------------\n",
      "              Coef.   Std.Err.   z   P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept     562.265   85.147 6.603 0.000 395.380 729.150\n",
      "pitch          11.400    5.119 2.227 0.026   1.367  21.434\n",
      "yaw             5.191    5.182 1.002 0.316  -4.965  15.348\n",
      "roll           24.236    5.229 4.635 0.000  13.988  34.484\n",
      "Group Var   59603.008 1249.988                            \n",
      "==========================================================\n",
      "\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:            MixedLM Dependent Variable: prediction_x\n",
      "No. Observations: 630     Method:             REML        \n",
      "No. Groups:       10      Scale:              525.9987    \n",
      "Min. group size:  63      Log-Likelihood:     -2896.9324  \n",
      "Max. group size:  63      Converged:          Yes         \n",
      "Mean group size:  63.0                                    \n",
      "----------------------------------------------------------\n",
      "              Coef.   Std.Err.   z   P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept     562.265   85.147 6.603 0.000 395.380 729.150\n",
      "pitch          11.400    5.119 2.227 0.026   1.367  21.434\n",
      "yaw             5.191    5.182 1.002 0.316  -4.965  15.348\n",
      "roll           24.236    5.229 4.635 0.000  13.988  34.484\n",
      "Group Var   59603.008 1249.988                            \n",
      "==========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 合成dataframe\n",
    "subjects = []\n",
    "pitch = []\n",
    "yaw = []\n",
    "roll = []\n",
    "preds = []\n",
    "for data in condit_dict:\n",
    "    subjects.append(data.image_name)\n",
    "    euler = warp_norm.hr_to_pitchyaw(data.hr)\n",
    "    pitch.append(euler[0,0])\n",
    "    yaw.append(euler[0,1])\n",
    "    roll.append(euler[0,2])\n",
    "    preds.append(data.gaze_point+org_tan)\n",
    "\n",
    "preds = np.asarray(preds)\n",
    "data = {\n",
    "    'subject_id': subjects,\n",
    "    'pitch': pitch,\n",
    "    'yaw': yaw,\n",
    "    'roll': roll,\n",
    "    'prediction_x': preds[:,0],\n",
    "    'prediction_y': preds[:,1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "formula = 'prediction_x ~ pitch + yaw + roll'\n",
    "model_x = smf.mixedlm(formula, data=data, groups=data['subject_id'])\n",
    "model_y = smf.mixedlm(formula, data=data, groups=data['subject_id'])\n",
    "\n",
    "\n",
    "result_x = model_x.fit()\n",
    "result_y = model_y.fit()\n",
    "\n",
    "# 打印方差分析结果\n",
    "print(result_x.summary())\n",
    "print(result_y.summary())\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gazeE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
