{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warp_norm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/hgh/hghData/Datasets/preprocessed_labels.csv')\n",
    "image_path = data.loc[:, 'image_path']\n",
    "label = data.loc[:, 'label']\n",
    "results = np.loadtxt('./results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(image_path[105])\n",
    "print(label[105])\n",
    "cleaned_string = label[105].replace('\\n', '').replace(' ', '')\n",
    "# 将字符串切分成单个数字的列表\n",
    "numbers = cleaned_string.split('][')\n",
    "numbers[0] = numbers[0].lstrip('[')\n",
    "numbers[-1] = numbers[-1].rstrip(']')\n",
    "# 将字符串转换为浮点数，并重新组成 NumPy 数组\n",
    "numpy_array = np.array([float(num) for num in numbers]).reshape(3,1)\n",
    "gaze_img = warp_norm.draw_gaze(img, numpy_array, color = (0,255,0))\n",
    "gaze_img = warp_norm.draw_gaze(img, results[105])\n",
    "plt.imshow(cv2.cvtColor(gaze_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "csv_file_path = '/home/hgh/hghData/Datasets/preprocessed_labels.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "dataset_dict = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    cleaned_string = label.replace('\\n', '').replace(' ', '')\n",
    "    # 将字符串切分成单个数字的列表\n",
    "    numbers = cleaned_string.split('][')\n",
    "    numbers[0] = numbers[0].lstrip('[')\n",
    "    numbers[-1] = numbers[-1].rstrip(']')  \n",
    "    # 组织样本信息为字典\n",
    "    label_array = np.array([float(num) for num in numbers]).reshape(3,1)\n",
    "    sample_info = {\n",
    "        'image_path': image_path,\n",
    "        'label': label_array\n",
    "    }\n",
    "\n",
    "    # 将样本信息加入数据集字典，以索引作为键\n",
    "    dataset_dict[index] = sample_info\n",
    "\n",
    "# for key, value in dataset_dict.items():\n",
    "#     print(f\"Sample {key}: {value}\")\n",
    "\n",
    "pickle_file_path = '/home/hgh/hghData/Datasets/dataset_dict.pkl'\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(dataset_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31945605309159664\n",
      "631.9514661274015\n",
      "[ 4.32886754e+01  1.93693124e+02 -1.13686838e-13]\n",
      "[ 701.34267642 1400.89825287]\n"
     ]
    }
   ],
   "source": [
    "import warp_norm\n",
    "import numpy as np\n",
    "gv = np.array([0.0685,0.3065,-0.94944])\n",
    "if gv.size == 2:\n",
    "    gv = warp_norm.pitchyaw_to_vector(gv)\n",
    "z = np.array([0,0,-600])\n",
    "theta = np.arcsin(np.linalg.norm(np.cross(gv,z))/(np.linalg.norm(gv)*np.linalg.norm(z)))\n",
    "print(theta)\n",
    "scale = np.linalg.norm(z)/(np.cos(theta)*np.linalg.norm(gv))\n",
    "print(scale)\n",
    "gp = scale * gv - z\n",
    "print(gp)\n",
    "gp = np.delete(gp, 2, axis=0)\n",
    "t = np.array([0.215,0.215])\n",
    "s = np.array([500,500])\n",
    "print(gp/t+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636]\n",
      "[[-0.22497383 -0.2523082 ]\n",
      " [-0.23685605  0.04697659]\n",
      " [-0.35651399  0.16178618]\n",
      " ...\n",
      " [-0.13845209 -0.33410653]\n",
      " [-0.21863731  0.2093067 ]\n",
      " [-0.3591192   0.07912455]]\n",
      "[[-0.14345832 -0.16445599]\n",
      " [-0.19170144 -0.01741143]\n",
      " [-0.10249488  0.09203888]\n",
      " ...\n",
      " [-0.48741466 -0.46078506]\n",
      " [-0.47450206  0.26392451]\n",
      " [-0.35260439  0.06243787]]\n",
      "Tan error: 11.047553826567118\n",
      "Tan error: 11.809294488892363\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warp_norm\n",
    "import utils\n",
    "\n",
    "pickle_file_path = '/home/hgh/hghData/Datasets/dataset_dict.pkl'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_dataset_dict = pickle.load(file)\n",
    "ground_truth = []\n",
    "idx = 0\n",
    "tan_list = []\n",
    "for key, value in loaded_dataset_dict.items():\n",
    "    # print(f\"Sample {key}: {value}\")\n",
    "    # 取出男生的数据\n",
    "    image_name = os.path.basename(value['image_path'])\n",
    "    # print(image_name)\n",
    "    number = int((int(os.path.splitext(image_name)[0][19:]) - 1)/100)\n",
    "    if number % 2 == 0:\n",
    "        tan_list.append(idx)\n",
    "    ground_truth.append(value['label'].reshape((1,3))[0])\n",
    "    idx+=1\n",
    "ground_truth = np.array(ground_truth)\n",
    "print(tan_list)\n",
    "ground_truth = warp_norm.vector_to_pitchyaw(-ground_truth)\n",
    "print(ground_truth)\n",
    "\n",
    "pred = []\n",
    "pred_path = './results.txt'\n",
    "\n",
    "with open(pred_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    data_array = [float(x) for x in line.split()]\n",
    "    pred.append(data_array)\n",
    "pred = np.array(pred)\n",
    "print(pred)\n",
    "\n",
    "ground_truth_tan = ground_truth[tan_list]\n",
    "pred_tan = pred[tan_list]\n",
    "\n",
    "mask = np.isin(np.arange(len(ground_truth)), tan_list, invert=True)\n",
    "ground_truth_chen = ground_truth[mask]\n",
    "pred_chen = pred[mask]\n",
    "\n",
    "\n",
    "e_tan = utils.angular_error(ground_truth_tan,pred_tan)\n",
    "print('Tan error:', np.mean(e_tan))\n",
    "\n",
    "\n",
    "e_chen = utils.angular_error(ground_truth_chen,pred_chen)\n",
    "print('Chen error:', np.mean(e_chen))\n",
    "\n",
    "e = utils.angular_error(ground_truth,pred)\n",
    "print('Total error:', np.mean(e))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GazeNormalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
