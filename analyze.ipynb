{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warp_norm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/hgh/hghData/Datasets/preprocessed_labels.csv')\n",
    "image_path = data.loc[:, 'image_path']\n",
    "label = data.loc[:, 'label']\n",
    "results = np.loadtxt('./results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(image_path[105])\n",
    "print(label[105])\n",
    "cleaned_string = label[105].replace('\\n', '').replace(' ', '')\n",
    "# 将字符串切分成单个数字的列表\n",
    "numbers = cleaned_string.split('][')\n",
    "numbers[0] = numbers[0].lstrip('[')\n",
    "numbers[-1] = numbers[-1].rstrip(']')\n",
    "# 将字符串转换为浮点数，并重新组成 NumPy 数组\n",
    "numpy_array = np.array([float(num) for num in numbers]).reshape(3,1)\n",
    "gaze_img = warp_norm.draw_gaze(img, numpy_array, color = (0,255,0))\n",
    "gaze_img = warp_norm.draw_gaze(img, results[105])\n",
    "plt.imshow(cv2.cvtColor(gaze_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "csv_file_path = '/home/hgh/hghData/Datasets/preprocessed_labels.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "dataset_dict = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    cleaned_string = label.replace('\\n', '').replace(' ', '')\n",
    "    # 将字符串切分成单个数字的列表\n",
    "    numbers = cleaned_string.split('][')\n",
    "    numbers[0] = numbers[0].lstrip('[')\n",
    "    numbers[-1] = numbers[-1].rstrip(']')  \n",
    "    # 组织样本信息为字典\n",
    "    label_array = np.array([float(num) for num in numbers]).reshape(3,1)\n",
    "    sample_info = {\n",
    "        'image_path': image_path,\n",
    "        'label': label_array\n",
    "    }\n",
    "\n",
    "    # 将样本信息加入数据集字典，以索引作为键\n",
    "    dataset_dict[index] = sample_info\n",
    "\n",
    "# for key, value in dataset_dict.items():\n",
    "#     print(f\"Sample {key}: {value}\")\n",
    "\n",
    "pickle_file_path = '/home/hgh/hghData/Datasets/dataset_dict.pkl'\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(dataset_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31945605309159664\n",
      "631.9514661274015\n",
      "[ 4.32886754e+01  1.93693124e+02 -1.13686838e-13]\n",
      "[ 701.34267642 1400.89825287]\n"
     ]
    }
   ],
   "source": [
    "import warp_norm\n",
    "import numpy as np\n",
    "gv = np.array([0.0685,0.3065,-0.94944])\n",
    "if gv.size == 2:\n",
    "    gv = warp_norm.pitchyaw_to_vector(gv)\n",
    "z = np.array([0,0,-600])\n",
    "theta = np.arcsin(np.linalg.norm(np.cross(gv,z))/(np.linalg.norm(gv)*np.linalg.norm(z)))\n",
    "print(theta)\n",
    "scale = np.linalg.norm(z)/(np.cos(theta)*np.linalg.norm(gv))\n",
    "print(scale)\n",
    "gp = scale * gv - z\n",
    "print(gp)\n",
    "gp = np.delete(gp, 2, axis=0)\n",
    "t = np.array([0.215,0.215])\n",
    "s = np.array([500,500])\n",
    "print(gp/t+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22497383 -0.2523082 ]\n",
      " [-0.23685605  0.04697659]\n",
      " [-0.35651399  0.16178618]\n",
      " ...\n",
      " [-0.13845209 -0.33410653]\n",
      " [-0.21863731  0.2093067 ]\n",
      " [-0.3591192   0.07912455]]\n",
      "[[-0.14345832 -0.16445599]\n",
      " [-0.19170144 -0.01741143]\n",
      " [-0.10249488  0.09203888]\n",
      " ...\n",
      " [-0.48741466 -0.46078506]\n",
      " [-0.47450206  0.26392451]\n",
      " [-0.35260439  0.06243787]]\n",
      "error: 11.809294488892363\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warp_norm\n",
    "import utils\n",
    "\n",
    "pickle_file_path = '/home/hgh/hghData/Datasets/dataset_dict.pkl'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_dataset_dict = pickle.load(file)\n",
    "ground_truth = []\n",
    "for key, value in loaded_dataset_dict.items():\n",
    "    # print(f\"Sample {key}: {value}\")\n",
    "    ground_truth.append(value['label'].reshape((1,3))[0])\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "ground_truth = warp_norm.vector_to_pitchyaw(-ground_truth)\n",
    "print(ground_truth)\n",
    "\n",
    "pred = []\n",
    "pred_path = './results.txt'\n",
    "\n",
    "with open(pred_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    data_array = [float(x) for x in line.split()]\n",
    "    pred.append(data_array)\n",
    "pred = np.array(pred)\n",
    "print(pred)\n",
    "\n",
    "e = utils.angular_error(ground_truth,pred)\n",
    "print('error:', np.mean(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GazeNormalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
